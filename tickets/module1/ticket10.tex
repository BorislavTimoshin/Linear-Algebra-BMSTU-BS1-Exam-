\section{
    Евклидово пространство. Ортонормированный базис. Процесс ортогонализации Грама-Шмидта, вывод формулы. Построение ортонормированного базиса.
}

\subsection{
    Евклидово пространство.
}

\begin{definition}
    Отображение $\mathcal{V} \times \mathcal{V} \to \RR$, где $\mathcal{V}$ - линейное пространство над полем $\RR$, называется \textbf{\textit{скалярным произведением}}, если выполнены 4 аксиомы:
    \begin{enumerate}[nosep]
        \item $(\vec{x}, \vec{y}) = (\vec{y}, \vec{x})$.
        \item $(\vec{x} + \vec{y}, \vec{z}) = (\vec{x}, \vec{z}) + (\vec{y}, \vec{z})$ - аддитивность по первому аргументу.
        \item $(\alpha \vec{x}, \vec{y}) = \alpha(\vec{x}, \vec{y})$ - однородность по первому аргументу.
        \item $(\vec{x}, \vec{x}) \geq 0$, причем $(\vec{x}, \vec{x}) = 0 \iff \vec{x} = 0$.
    \end{enumerate}
\end{definition}

\begin{definition}
    Вещественное линейное пространство с так введенным скалярным произведением называется \textbf{\textit{евклидовым пространством}}.
\end{definition}

\subsection{
    Ортонормированный базис.
}

\begin{definition}
    Векторы $\vec{x}$ и $\vec{y}$ называются \textbf{\textit{ортогональными}}, если $(\vec{x}, \vec{y}) = 0$.
\end{definition}

\begin{definition}
    Система векторов называется \textit{\textbf{ортогональной}}, если все векторы в ней попарно ортогональны.
\end{definition}

\begin{definition}
    Система векторов называется \textit{\textbf{ортонормированной}}, если она ортогональна и норма каждого вектора равна 1.
\end{definition}


\newpage


\subsection{
    Процесс ортогонализации Грама-Шмидта, вывод формулы. Построение ортонормированного базиса.
}

Построить ортонормированный базис можно, отталкиваясь от некоторого исходного базиса, при помощи алгоритма, который называют процессом ортогонализации Грама-Шмидта:

\bigbreak

Пусть $f = (\vec{f_1}, \ldots, \vec{f_n})$ - некоторый базис в евклидовом $n$-мерном пространстве $\mathcal{E}$. Модифицируя этот базис, мы будем строить новый базис $e = (\vec{e_1}, \ldots, \vec{e_n})$, который будет ортонормированным. Последовательно вычисляем векторы $\vec{g_1}$ и $\vec{e_1}$, $\vec{g_2}$ и $\vec{e_2}$ и т.д. по формулам:

\begin{align*}
    \vec{g_1} = \vec{f_1}, \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad
    \quad \quad \quad \quad \quad \thinspace \thinspace \thinspace \thinspace \thinspace \vec{e_1} = \frac{\vec{g_1}}{\norm{\vec{g_1}}};\\
    \vec{g_2} = \vec{f_2} - (\vec{f_2}, \vec{e_1}) \cdot \vec{e_1}, \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad
    \quad \quad \quad \quad \thinspace \thinspace \thinspace \thinspace \thinspace \vec{e_2} = \frac{\vec{g_2}}{\norm{\vec{g_2}}};\\
    \vec{g_3} = \vec{f_3} - (\vec{f_3}, \vec{e_1}) \cdot \vec{e_1} - (\vec{f_3}, \vec{e_2}) \cdot \vec{e_2}, \quad \quad \quad \quad \quad \quad \quad \quad \thinspace \thinspace \thinspace \thinspace \thinspace \vec{e_3} = \frac{\vec{g_3}}{\norm{\vec{g_3}}};\\
    \ldots \ldots \ldots \ldots \ldots \ldots \ldots
    \ldots \ldots \ldots \ldots
    \quad \quad \quad \quad \quad \quad
    \quad \quad \quad \quad
    \ldots \ldots \ldots \\
    \vec{g_n} = \vec{f_n} - (\vec{f_n}, \vec{e_1}) \cdot \vec{e_1} - \ldots - (\vec{f_n}, \vec{e}_{n - 1}) \cdot \vec{e}_{n - 1}, \quad \quad \quad \thinspace \thinspace \thinspace \vec{e_n} = \frac{\vec{g_n}}{\norm{\vec{g_n}}}.
\end{align*}

\begin{proof}~

    Рассмотрим индукцию по количеству векторов $n$.
    \begin{enumerate}
        \item При $n = 1$ утверждение очевидно.
        \item Пусть это утверждение выполнено для количества векторов, равного $n$, докажем его для $n + 1$. 
        
        Т.к. утверждение верно для $n$ векторов, то мы можем считать, что векторы $\vec{g_1}, \ldots, \vec{g_n}$ с указанными свойствами уже построены. Построим вектор $\vec{g}_{n + 1}$ в виде 
        $$\vec{g}_{n + 1} = \vec{f}_{n + 1} + \lambda_1 \vec{g_1} + \ldots + \lambda_n\vec{g_n}.$$ 
        Линейная оболочка векторов $\vec{g_1}, \ldots,  \vec{g}_{n + 1}$ совпадает с $\vec{f_1}, \ldots, \vec{f}_{n + 1}$ при любых $i$, поэтому мы будем подбирать коэффициенты $\lambda_i$ так, чтобы выполнялось условие $(\vec{g}_{n + 1},  \vec{g_i}) = 0$ для всех $i = 1, \ldots, n$. Рассмотрим скалярное произведение $$0 = (\vec{g}_{n + 1}, \vec{g_i}) = (\vec{f}_{n + 1}, \vec{g_i})+ \lambda_1(\vec{g_1}, \vec{g_i}) + \ldots + \lambda_n(\vec{g_n}, \vec{g_i}).$$
        Поскольку $(\vec{g_j}, \vec{g_i}) = 0$ при $j = i$ по предположению индукции, то 
        $$0 = (\vec{f}_{n + 1}, \vec{g_i}) + \lambda_i(\vec{g_i}, \vec{g_i}),$$ следовательно 
        $$\lambda_i = -\frac{(\vec{f}_{n + 1}, \vec{g_i})}{(\vec{g_i}, \vec{g_i})} \text{ (знаменатель отличен от нуля).}$$ 
        
        Таким образом, чтобы получить вектор $\vec{g}_{n + 1}$, надо из вектора $\vec{f}_{n + 1}$ вычесть его ортогональные проекции на векторы $\vec{g_1}, \ldots, \vec{g_n}$:
        $$\vec{g}_{n + 1} = \vec{f}_{n + 1} -\frac{(\vec{f}_{n + 1}, \vec{g_1})}{(\vec{g_1}, \vec{g_1})} \cdot \vec{g_1} - \ldots -\frac{(\vec{f}_{n + 1}, \vec{g_n})}{(\vec{g_n}, \vec{g_n})} \cdot \vec{g_n}.$$
    \end{enumerate}
\end{proof}


\newpage


\subsection{*Полезные факты, которые тоже будут на экзамене.}

\begin{definition}
    Линейные подпространства $\mathcal{L}_1$ и $\mathcal{L}_2$ называются \textbf{\textit{ортогональными}}, если $\forall \vec{x} \in \mathcal{L}_1, \forall \vec{y} \in \mathcal{L}_2 \colon \vec{x} \perp \vec{y}$.
\end{definition}

\begin{theorem}
    Любая ортогональная система ненулевых векторов линейно независима.
\end{theorem}

\begin{proof}
    Рассмотрим произвольную ортогональную систему ненулевых векторов $\vec{e_1}, \ldots, \vec{e_m}$. Предположим, что для действительных коэффициентов $\alpha_1, \ldots, \alpha_m$ выполняется равенство
    \begin{equation}
        \alpha_1\vec{e_1} + \ldots + \alpha_m\vec{e_m} = \vec{0}.
        \label{eq:theorem_10_1_1}
    \end{equation}
    Умножим это равенство скалярно на какой-либо вектор $\vec{e_i}$:
    $$(\alpha_1\vec{e_1} + \ldots + \alpha_m\vec{e_m}, \vec{e_i}) = (\vec{0}, \vec{e_i}).$$
    $$\alpha_1(\vec{e_1}, \vec{e_i}) + \ldots + \alpha_i(\vec{e_i}, \vec{e_i}) + \ldots + \alpha_m(\vec{e_m}, \vec{e_i}) = 0.$$
    Так как система ортогональна, то все слагаемые слева, кроме одного, равны нулю, т.е.
    \begin{equation}
        \alpha_i(\vec{e_i}, \vec{e_i}) = 0.
        \label{eq:theorem_10_1_2}
    \end{equation}
    Так как вектор $\vec{e_i}$ ненулевой, то $(\vec{e_i}, \vec{e_i}) \ne 0$. Поэтому из $\eqref{eq:theorem_10_1_2}$ следует, что $\alpha_i = 0$. Индекс $i$ можно было выбирать произвольно, так что на самом деле все коэффициенты $a_i$ являются нулевыми. Значит, равенство $\eqref{eq:theorem_10_1_1}$ возможно лишь при нулевых коэффициентах. Значит, система векторов $\vec{e_1}, \ldots, \vec{e_m}$ линейно независима.
\end{proof}

\begin{corollary}
    Ортонормированная система векторов линейно независима. 
\end{corollary}

\begin{corollary}
    В $n$-мерном пространстве ортогональная/ортонормированная система из $n$ векторов является базисом.
\end{corollary}

\begin{definition}
    Если базис евклидова пространства представляет собой ортогональную систему векторов, то этот базис называют \textbf{\textit{ортогональным}}.
\end{definition}

\begin{definition}
    Ортогональный базис называется \textbf{\textit{ортонормированным}}, если каждый вектор этого базиса имеет норму (длину), равную единице.
\end{definition}

\begin{theorem}
    В конечномерном евклидовом пространстве существует ортонормированный базис.
\end{theorem}
